{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46992cc7",
   "metadata": {},
   "source": [
    "# Pre-need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc3596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "import collections\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from ucimlrepo import fetch_ucirepo   \n",
    "import math\n",
    "\n",
    "def order(attri,i,datax):\n",
    "    for j in range(len(datax[i])):\n",
    "        if(attri == datax[i][j]):\n",
    "            return j\n",
    "        \n",
    "def attri(x, i, datax):\n",
    "    return datax[i][x]\n",
    "def get_s(X, loca):\n",
    "    s = []\n",
    "    if(loca > X.shape[1]):\n",
    "        return s\n",
    "    else:\n",
    "        for i in range(X.shape[1]):\n",
    "            if(i>=loca):\n",
    "                s.append(X.iloc[:, i].value_counts().index)\n",
    "        for i in range(X.shape[1]-loca):\n",
    "            s[i] = np.sort(s[i]) \n",
    "        return s  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1711f5",
   "metadata": {},
   "source": [
    "# CADM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98bd97b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mutual_infoa(cen, q, attr_idx, intra_dis, opt):\n",
    "\n",
    "    gama_cen = intra_dis[attr_idx][cen]\n",
    "    if(opt == True):\n",
    "        gama_q = intra_dis[attr_idx][q]\n",
    "    else:\n",
    "        gama_q = 1/intra_dis[attr_idx][q]\n",
    "        \n",
    "    mi_pq = gama_cen + gama_q\n",
    "    \n",
    "    return  mi_pq\n",
    "\n",
    "def pairwise_distance_ca2(X, Cen,k1,data,location,datax,importance_freq,intra_dis,opt):\n",
    "    \"\"\"\n",
    "    :param X: sample\n",
    "    :param Cen: centroid\n",
    "    :return: the distance between two objects\n",
    "    \"\"\"\n",
    "    n = X.shape[1]\n",
    "    distance = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        p = X[:,i]\n",
    "        qc = Cen[:,i]\n",
    "        if(i >=location):\n",
    "            if(p == qc):\n",
    "                distance += 0\n",
    "            else:\n",
    "                rank1 = order(p, i-location,datax) #order function \n",
    "                rankc = order(qc, i-location, datax)\n",
    "                diff = abs(rank1-rankc) \n",
    "                first = np.min([rank1, rankc])  \n",
    "                gama_cen = intra_dis[i][qc[0]]\n",
    "                self = False\n",
    "\n",
    "                for j in range(0,diff+1):\n",
    "                    loc1 = first + j\n",
    "                    it = attri(loc1, i-location, datax) #attri return attribut\n",
    "                    \n",
    "                    if(it != qc[0]):\n",
    "                        mutual_info = weighted_mutual_infoa(qc[0],it, i, intra_dis, opt)\n",
    "                        distance += mutual_info\n",
    "#                 distance = distance/(diff)\n",
    "                distance += importance_freq[i]*importance_freq[i]\n",
    "                \n",
    "        else:\n",
    "            if(p == qc):\n",
    "                distance += 0\n",
    "            else:\n",
    "                self = True\n",
    "\n",
    "                mutual_info = weighted_mutual_infoa(qc[0],p[0], i, intra_dis, opt)\n",
    "                distance += mutual_info + importance_freq[i]*importance_freq[i]\n",
    "            \n",
    "    return distance        \n",
    "            \n",
    "def cluster_data_ca2(rs,df, location, datax, k1):   \n",
    " # k centers\n",
    "    k = k1\n",
    "    centroids = df.sample(k, random_state=rs).to_numpy()#1647\n",
    "#     centroids = df.iloc[[0, 2, 4]].to_numpy()\n",
    "    prev_centroids = centroids.copy()\n",
    "    \n",
    "    importance_freq = []\n",
    "    intra_dis = []\n",
    "    convergence = []\n",
    "    \n",
    "        \n",
    "    for i1 in range(k):\n",
    "        importance_freq.append({})\n",
    "        intra_dis.append([])\n",
    "        for j in range(df.shape[1]):\n",
    "            intra_dis[i1].append({})\n",
    "                       \n",
    "                            \n",
    "    labels = np.zeros(df.shape[0], dtype=int)\n",
    "    cns = df.shape[0]\n",
    "    \n",
    "    min_distance = [float('inf')] * df.shape[0]\n",
    "    opt = False\n",
    "#     print(corr_vec)\n",
    "    for turn in range(100):\n",
    "        stable = True\n",
    "#         print(f\"Iteration {turn}\")\n",
    "        if(turn == 0):\n",
    "            opt = True\n",
    "        else:\n",
    "            opt = False\n",
    "        \n",
    "        for j in range(k):\n",
    "            if(turn > 0):\n",
    "                cluster_points = df[labels == j]\n",
    "            else:\n",
    "                cluster_points = df\n",
    "                    \n",
    "            for i in range(cluster_points.shape[1]):\n",
    "                counter = collections.Counter(cluster_points.iloc[:, i])\n",
    "                most_common_times = counter.most_common(1)[0][1]\n",
    "                for j1 in cluster_points.iloc[:, i].value_counts().index:\n",
    "                    intra_dis[j][i][j1] = cluster_points.iloc[:, i].value_counts()[j1]/cns\n",
    "\n",
    "            s_t = 0\n",
    "            for i1 in range(cluster_points.shape[1]):\n",
    "                 #importance\n",
    "                counter = collections.Counter(cluster_points.iloc[:, i1])\n",
    "                current_common_times = counter.most_common(1)[0][1]\n",
    "                s_t += current_common_times\n",
    "            for i1 in range(cluster_points.shape[1]):\n",
    "                counter = collections.Counter(cluster_points.iloc[:, i1])\n",
    "                current_common_times = counter.most_common(1)[0][1]   \n",
    "                importance_freq[j][i1] =  current_common_times/s_t\n",
    "                \n",
    "        for i in range(df.shape[0]):\n",
    "            for j in range(k):\n",
    "                if(turn > 0):\n",
    "                    cluster_points = df[labels == j]\n",
    "                else:\n",
    "                    cluster_points = df\n",
    "                distance = pairwise_distance_ca2(df.iloc[i:i+1].to_numpy(), centroids[j:j+1], k1,df,location, datax,importance_freq[j], intra_dis[j],opt)\n",
    "                if distance < min_distance[i]:\n",
    "                    min_distance[i] = distance\n",
    "                    labels[i] = j\n",
    "                    stable = False\n",
    "\n",
    "        for j in range(k):\n",
    "            cluster_points = df[labels == j]\n",
    "            if cluster_points.shape[0] > 0:\n",
    "                new_centroids = []\n",
    "                for col in df.columns:\n",
    "                    counter = collections.Counter(cluster_points[col])\n",
    "                    mode = counter.most_common(1)[0][0]\n",
    "                    new_centroids.append(mode)\n",
    "                centroids[j] = np.array(new_centroids)\n",
    "                \n",
    "         \n",
    "        if stable:\n",
    "            \n",
    "            break\n",
    "\n",
    "    return labels, centroids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c556f1f",
   "metadata": {},
   "source": [
    "# NMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "067dda74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "def nmi(y,cluster_labels,real): \n",
    "#     for i in range(len(real)):\n",
    "#         y.loc[y['class'] == real[i], 'class'] = i\n",
    "    y = y.squeeze() \n",
    "    for i in range(len(real)):\n",
    "        for j in range(len(real)):\n",
    "            if(cluster_labels[i] == j):\n",
    "                cluster_labels[i] = real[j]\n",
    "\n",
    "    mi = mutual_info_score(y, cluster_labels)\n",
    "\n",
    "    h_y = entropy(np.unique(y, return_counts=True)[1] / len(y))\n",
    "    h_y_pred = entropy(np.unique(cluster_labels, return_counts=True)[1] / len(cluster_labels))\n",
    "\n",
    "    nmi = mi / max(h_y, h_y_pred)\n",
    "\n",
    "    print(f\"NMI: {nmi:.3f}\")\n",
    "    return nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aff8cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nm_vo(y, cluster_labels):\n",
    "    y = y.squeeze() \n",
    "    vi1s = mutual_info_score(y, cluster_labels)\n",
    "    h_y = entropy(np.unique(y, return_counts=True)[1] / len(y))\n",
    "    h_y_pred = entropy(np.unique(cluster_labels, return_counts=True)[1] / len(cluster_labels))\n",
    "    return vi1s / max(h_y, h_y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a55a3ae",
   "metadata": {},
   "source": [
    "# CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc6a8b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal(X,y,cluster_labels):\n",
    "    a1 = []\n",
    "    z = []\n",
    "    real = []\n",
    "    y = y.reset_index(drop=True)\n",
    "    for i in range(len(y.value_counts())):\n",
    "        a = []\n",
    "        for i1 in range(X.shape[0]):\n",
    "            if(cluster_labels[i1] == i):\n",
    "                a.append(i1)\n",
    "        cnt = 0\n",
    "        z1 = 0\n",
    "        rea = 0\n",
    "        for j in range(len(y.value_counts())):\n",
    "            lo = y.value_counts().index[j][0]\n",
    "            one_index = y[y.iloc[:,0] == lo].index\n",
    "            cnt1 = 0\n",
    "            for i in a:\n",
    "                for j in one_index:\n",
    "                    if(i == j):\n",
    "                        cnt1 += 1\n",
    "            if(j == 0):\n",
    "                cnt = cnt1\n",
    "                rea = lo\n",
    "            else:\n",
    "                if(cnt<cnt1):\n",
    "                    s1 = False\n",
    "                    for j1 in z:\n",
    "                        if(j == j1):\n",
    "                            s1 = True\n",
    "                    if(s1 == False):\n",
    "                        cnt = cnt1\n",
    "                        z1 = j\n",
    "                        rea = lo\n",
    "\n",
    "        a1.append(cnt)\n",
    "        z.append(z1)\n",
    "        real.append(rea)\n",
    "        \n",
    "    cx = 0\n",
    "    for i in a1:\n",
    "        cx+=i\n",
    "    cs = cx/X.shape[0]\n",
    "    return cs,real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2b605a",
   "metadata": {},
   "source": [
    "# ARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99ba9bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "def ARI(cluster_labels,x):\n",
    "    x = x.squeeze()\n",
    "    ari = adjusted_rand_score(cluster_labels, x)\n",
    "    print(f\"Adjusted Rand Index (ARI): {ari:.3f}\")\n",
    "    return ari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10654bce",
   "metadata": {},
   "source": [
    "# Hayes (HA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67db910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "\n",
    "hayes_roth = fetch_ucirepo(id=44) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "\n",
    "X = hayes_roth.data.features \n",
    "y = hayes_roth.data.targets \n",
    "# delete null\n",
    "X = X.loc[~y.isnull().any(axis=1)]\n",
    "y = y.loc[~y.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948f047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "od = 2\n",
    "s = 0\n",
    "nm=0\n",
    "a=0\n",
    "for i in range(10):\n",
    "    cluster_labels, centroids = cluster_data_ca2(44,X,od,get_s(X, od),3)\n",
    "    cs, real = cal(X,y,cluster_labels)\n",
    "    hai1 =ARI(cluster_labels,y)\n",
    "    hi1 = nmi(y,cluster_labels,real)\n",
    "    s+=cs\n",
    "    a+=hai1\n",
    "    nm+=hi1 \n",
    "print(f'Accuracy: {s/10}')\n",
    "print(f'NMI: {nm/10}')\n",
    "print(f'ARI: {a/10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a879ff2",
   "metadata": {},
   "source": [
    "# LY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32a7681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "lymphography = fetch_ucirepo(id=63) \n",
    "  \n",
    "    \n",
    "# data (as pandas dataframes) \n",
    "X = lymphography.data.features \n",
    "y = lymphography.data.targets \n",
    "X = X.drop(X.columns[2], axis=1)\n",
    "X = X.drop(X.columns[-1], axis=1)\n",
    "X = X.drop(X.columns[11], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f1f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "od = 19\n",
    "s = 0\n",
    "nm=0\n",
    "a=0\n",
    "for i in range(10):\n",
    "    cluster_labels, centroids = cluster_data_ca2(91,X,od,get_s(X, od),4)\n",
    "    cs, real = cal(X,y,cluster_labels)\n",
    "    hai1 =ARI(cluster_labels,y)\n",
    "    hi1 = nmi(y,cluster_labels,real)\n",
    "    s+=cs\n",
    "    a+=hai1\n",
    "    nm+=hi1    \n",
    "print(f'Accuracy: {s/10}')\n",
    "print(f'NMI: {nm/10}')\n",
    "print(f'ARI: {a/10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a48af3",
   "metadata": {},
   "source": [
    "# Mass(MA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8e0e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "mammographic_mass = fetch_ucirepo(id=161) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = mammographic_mass.data.features \n",
    "y = mammographic_mass.data.targets \n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "X = X.drop(columns=['Age'])\n",
    "X = X[list(X.columns[1:3]) + [X.columns[0]] + [X.columns[3]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "od = 2\n",
    "s = 0\n",
    "nm=0\n",
    "a=0\n",
    "for i in range(10):\n",
    "    cluster_labels, centroids = cluster_data_ca2(59,X,od,get_s(X, od),2)\n",
    "    cs, real = cal(X,y,cluster_labels)\n",
    "    hai1 =ARI(cluster_labels,y)\n",
    "    hi1 = nmi(y,cluster_labels,real)\n",
    "    s+=cs\n",
    "    a+=hai1\n",
    "    nm+=hi1    \n",
    "print(f'Accuracy: {s/10}')\n",
    "print(f'NMI: {nm/10}')\n",
    "print(f'ARI: {a/10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cce551",
   "metadata": {},
   "source": [
    "# Primary(PR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db1bcafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "primary_tumor = fetch_ucirepo(id=83) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = primary_tumor.data.features \n",
    "y = primary_tumor.data.targets \n",
    "\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "d = y.value_counts()[y.value_counts() >= 9].index\n",
    "index = []\n",
    "for i in d:\n",
    "    index.extend(y.loc[y.iloc[:,0] == i[0], :].index)\n",
    "X = X.loc[index]\n",
    "y = y.loc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dca14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "od = 20\n",
    "s = 0\n",
    "nm=0\n",
    "a=0\n",
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "for i in range(10):\n",
    "    cluster_labels, centroids = cluster_data_ca2(46,X,od,get_s(X, od),5)\n",
    "    cs, real = cal(X,y,cluster_labels)\n",
    "    hai1 =ARI(cluster_labels,y)\n",
    "    hi1 = nmi(y,cluster_labels,real)\n",
    "    s+=cs\n",
    "    a+=hai1\n",
    "    nm+= hi1 \n",
    "print(f'Accuracy: {s/10}')\n",
    "print(f'NMI: {nm/10}')\n",
    "print(f'ARI: {a/10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b087f4cd",
   "metadata": {},
   "source": [
    "# Nursery(NS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52bd93c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nursery = fetch_ucirepo(id=76) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = nursery.data.features \n",
    "y = nursery.data.targets \n",
    "datax = [['usual', 'pretentious', 'great_pret'],\n",
    " ['proper', 'less_proper', 'improper', 'critical', 'very_crit'],\n",
    " ['complete', 'completed', 'incomplete', 'foster'],\n",
    " ['1', '2', '3', 'more'],\n",
    " ['convenient', 'less_conv', 'critical'],\n",
    " ['inconv', 'convenient'],\n",
    " ['nonprob', 'slightly_prob', 'problematic'],\n",
    " ['not_recom', 'recommended', 'priority']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7263a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "od = 0\n",
    "cluster_labels, centroids = cluster_data_ca2(17,X,od,datax,4)\n",
    "cs, real = cal(X,y,cluster_labels)\n",
    "hai1 =ARI(cluster_labels,y)\n",
    "# y = y.squeeze() \n",
    "# ni1s = mutual_info_score(cluster_labels,y)\n",
    "# h_y = entropy(np.unique(y, return_counts=True)[1] / len(y))\n",
    "# h_y_pred = entropy(np.unique(cluster_labels, return_counts=True)[1] / len(cluster_labels))\n",
    "# ni1 = ni1s / max(h_y, h_y_pred)\n",
    "ni1 = nm_vo(y, cluster_labels)\n",
    "print(f'Accuracy: {cs}')\n",
    "print(f'NMI: {ni1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f21abfc",
   "metadata": {},
   "source": [
    "# Lenses(LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca8ba3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "lenses = fetch_ucirepo(id=58) \n",
    "  \n",
    "# # data (as pandas dataframes) \n",
    "X = lenses.data.features \n",
    "y = lenses.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b949bb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "od = 4\n",
    "s = 0\n",
    "nm=0\n",
    "a=0\n",
    "for i in range(10):\n",
    "    cluster_labels, centroids = cluster_data_ca2(28,X,od,get_s(X, od),3)\n",
    "    cs, real = cal(X,y,cluster_labels)\n",
    "    hai1 =ARI(cluster_labels,y)\n",
    "    hi1 = nmi(y,cluster_labels,real)\n",
    "    s+=cs\n",
    "    a+=hai1\n",
    "    nm+=hi1    \n",
    "print(f'Accuracy: {s/10}')\n",
    "print(f'NMI: {nm/10}')\n",
    "print(f'ARI: {a/10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a1fd33",
   "metadata": {},
   "source": [
    "# Voting(VO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1949268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "congressional_voting_records = fetch_ucirepo(id=105) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = congressional_voting_records.data.features \n",
    "y = congressional_voting_records.data.targets \n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee2c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "od = 17\n",
    "s = 0\n",
    "nm=0\n",
    "a=0\n",
    "for i in range(10):\n",
    "    cluster_labels, centroids = cluster_data_ca2(72,X,od,get_s(X, od),2)\n",
    "    cs, real = cal(X,y,cluster_labels)\n",
    "    hai1 =ARI(cluster_labels,y)\n",
    "    s+=cs\n",
    "    a+=hai1\n",
    "    nm+= nm_vo(y, cluster_labels)\n",
    "print(f'Accuracy: {s/10}')\n",
    "print(f'NMI: {nm/10}')\n",
    "print(f'ARI: {a/10}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [pytorch]",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
